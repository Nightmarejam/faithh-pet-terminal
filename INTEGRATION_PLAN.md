# ğŸ¯ FAITHH Frontend Integration & RAG Chat Plan

## ğŸ“Š Current State Assessment

### âœ… What We Have (Backend)
1. **Tool Execution System** âœ…
   - `tool_executor.py` - Complete engine
   - `executors/filesystem.py` - File operations
   - `executors/process.py` - Command execution
   - `faithh_api_websocket.py` - WebSocket + HTTP API

2. **RAG Infrastructure** âœ… (Already exists!)
   - `rag_api.py` - Flask API for RAG search
   - `rag_processor.py` - Document processing
   - `search_ui.py` - Streamlit search interface
   - `setup_rag.py` - RAG setup scripts
   - ChromaDB integration (port 8000)
   - Ollama embeddings (nomic-embed, port 11435)

3. **Existing UI** âœ…
   - `rag-chat.html` - HTML/JS chat interface (506 lines!)
   - Connected to RAG backend
   - Model selector (Gemini/Ollama)
   - RAG toggle

### âŒ What's Missing
1. Connection between tool system and chat UI
2. Unified API that combines chat + RAG + tools
3. Streamlit chat experience (you want this!)
4. Git tracking of progress

---

## ğŸ¯ Goal: Seamless Chat Experience

### What "Seamless" Means:
```
User types message
    â†“
System decides: RAG needed? Tools needed? Just chat?
    â†“
Executes appropriate actions
    â†“
Streams response back in real-time
    â†“
Beautiful UI shows everything
```

---

## ğŸ—ï¸ Architecture Plan

### Option A: Unified API (RECOMMENDED)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Streamlit Chat UI (New!)                   â”‚
â”‚  Beautiful, fast, easy to iterate                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     UNIFIED FAITHH API (faithh_unified_api.py)      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Chat Orchestrator                            â”‚ â”‚
â”‚  â”‚  â€¢ Decides: RAG? Tools? Just chat?            â”‚ â”‚
â”‚  â”‚  â€¢ Streams responses                          â”‚ â”‚
â”‚  â”‚  â€¢ Handles context                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚              â”‚              â”‚
   â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gemini â”‚  â”‚ RAG      â”‚  â”‚ Tool System  â”‚
â”‚ Chat   â”‚  â”‚ Search   â”‚  â”‚ (Executors)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits**:
- Single endpoint for everything
- Smart routing
- Clean architecture
- Easy to extend

### Option B: Keep Separate (Current)
```
Streamlit UI â†’ Multiple backends
    â”œâ†’ faithh_api_websocket.py (tools + chat)
    â””â†’ rag_api.py (RAG search)
```

**Issues**:
- Multiple connections
- Complex coordination
- Harder to maintain

---

## ğŸ¨ Streamlit Chat UI Design

### Core Features:
1. **Chat Interface**
   - Message history
   - Streaming responses
   - Code highlighting
   - File attachments

2. **RAG Integration**
   - Auto-search on relevant queries
   - Show source documents
   - Similarity scores
   - Toggle RAG on/off

3. **Tool Execution**
   - Show tool calls in chat
   - Display results inline
   - Progress indicators
   - Error handling

4. **Settings Panel**
   - Model selection (Gemini/Ollama)
   - RAG settings (# results, threshold)
   - Tool permissions
   - Theme toggle

---

## ğŸ”§ Implementation Steps

### Phase 1: Git Setup (5 min)
```bash
cd ~/ai-stack
git add .
git commit -m "feat: complete tool execution system with docs"
git push
```

### Phase 2: Create Unified API (30 min)
File: `faithh_unified_api.py`

**Components**:
1. Chat orchestrator
2. RAG integration (from existing rag_api.py)
3. Tool execution (from faithh_api_websocket.py)
4. Smart routing logic
5. Streaming responses

**Pseudocode**:
```python
async def handle_message(message, context):
    # 1. Analyze message
    needs_rag = should_use_rag(message)
    needs_tools = detect_tool_needs(message)
    
    # 2. Get RAG context if needed
    if needs_rag:
        rag_results = await search_rag(message)
        context.add(rag_results)
    
    # 3. Generate response with Gemini
    response = await gemini.generate(message, context)
    
    # 4. Execute tools if mentioned
    if needs_tools:
        tool_results = await execute_tools(response)
        response.append(tool_results)
    
    # 5. Stream back to UI
    yield response
```

### Phase 3: Streamlit Chat UI (45 min)
File: `chat_ui.py`

**Features**:
```python
import streamlit as st

# Layout
st.title("ğŸ’¬ FAITHH Chat")
st.caption("AI with RAG + Tools")

# Sidebar
with st.sidebar:
    model = st.selectbox("Model", ["Gemini", "Ollama"])
    use_rag = st.toggle("Enable RAG", value=True)
    use_tools = st.toggle("Enable Tools", value=True)

# Chat interface
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])
        if msg.get("sources"):
            with st.expander("ğŸ“š Sources"):
                for src in msg["sources"]:
                    st.markdown(f"- {src}")

# Input
if prompt := st.chat_input("Ask anything..."):
    # Send to unified API
    response = call_unified_api(prompt, use_rag, use_tools)
    # Stream response
    with st.chat_message("assistant"):
        st.write_stream(response)
```

### Phase 4: Connect Everything (20 min)
1. Update unified API endpoints
2. Test Streamlit â†’ API connection
3. Verify RAG integration
4. Test tool execution from chat

### Phase 5: Polish (30 min)
1. Error handling
2. Loading states
3. Source citations
4. Tool execution UI
5. Settings persistence

---

## ğŸ“ New Files to Create

1. **`faithh_unified_api.py`** (~300 lines)
   - Combines: chat, RAG, tools
   - Single endpoint: `/api/chat`
   - WebSocket: `/ws/chat` (streaming)

2. **`chat_ui.py`** (~200 lines)
   - Streamlit interface
   - Clean, modern design
   - Real-time streaming

3. **`chat_orchestrator.py`** (~150 lines)
   - Smart routing logic
   - Context management
   - RAG decision making

4. **`.gitignore`** (if not exists)
   - venv/
   - __pycache__/
   - *.pyc
   - .env

---

## ğŸ¯ RAG Integration Details

### When to Use RAG:
```python
def should_use_rag(message: str) -> bool:
    # Use RAG for:
    # - Questions about past conversations
    # - "Remember when..." queries
    # - Document references
    # - Knowledge retrieval
    
    rag_keywords = [
        'remember', 'told you', 'said', 'mentioned',
        'conversation', 'chat', 'discussed',
        'document', 'file', 'note'
    ]
    
    return any(kw in message.lower() for kw in rag_keywords)
```

### RAG Response Format:
```python
{
    "answer": "Based on your documents...",
    "sources": [
        {
            "content": "...",
            "metadata": {...},
            "score": 0.85
        }
    ],
    "used_rag": True
}
```

---

## ğŸ”¨ Tool Integration in Chat

### Tool Detection:
```python
def detect_tool_needs(message: str) -> List[str]:
    # Detect tool mentions:
    tools = []
    
    if 'read' in message and 'file' in message:
        tools.append('read_file')
    if 'run' in message or 'execute' in message:
        tools.append('run_command')
    if 'list' in message and ('files' in message or 'directory' in message):
        tools.append('list_directory')
    
    return tools
```

### Tool Execution UI:
```
User: "Read the config.yaml file"
    â†“
Assistant: "I'll read that file for you."
    [ğŸ”§ Executing: read_file(path=config.yaml)]
    â†“
    [âœ… Success: Read 1252 bytes, 64 lines]
    â†“
Assistant: "Here's what I found in config.yaml:
    - Security settings: 3 allowed directories...
    - Tool timeout: 30000ms
    - ..."
```

---

## ğŸ’¾ Git Commit Strategy

### Commit Points:
1. **Now**: "feat: complete tool execution system"
2. **After unified API**: "feat: create unified API with RAG + tools"
3. **After Streamlit UI**: "feat: add Streamlit chat interface"
4. **After integration**: "feat: connect UI to unified backend"
5. **After polish**: "polish: improve UX and error handling"

### Example Commits:
```bash
git add .
git commit -m "feat: complete tool execution system with docs

- Created tool_executor.py (226 lines)
- Added filesystem and process executors
- Implemented WebSocket API
- All tests passing
- Comprehensive documentation"

git push
```

---

## ğŸš€ Quick Start Implementation

### Fastest Path (2 hours):
1. âœ… Git commit current work (5 min)
2. âœ… Create `faithh_unified_api.py` (30 min)
3. âœ… Create `chat_ui.py` (45 min)
4. âœ… Connect and test (20 min)
5. âœ… Polish + commit (20 min)

### Result:
```
User opens: streamlit run chat_ui.py
    â†“
Beautiful chat interface
    â†“
Type: "What did I say about Docker?"
    â†“
System: Uses RAG â†’ Finds conversation â†’ Answers
    â†“
Type: "Read my config file"
    â†“
System: Executes tool â†’ Shows result â†’ Explains
```

---

## ğŸ“Š Expected Architecture

### Files After Integration:
```
ai-stack/
â”œâ”€â”€ faithh_unified_api.py      â† NEW! Single API
â”œâ”€â”€ chat_ui.py                  â† NEW! Streamlit UI
â”œâ”€â”€ chat_orchestrator.py        â† NEW! Smart routing
â”œâ”€â”€ tool_executor.py            â† Existing
â”œâ”€â”€ rag_api.py                  â† Merge into unified
â”œâ”€â”€ rag_processor.py            â† Keep for indexing
â”œâ”€â”€ search_ui.py                â† Optional: Keep or replace
â”œâ”€â”€ faithh_api_websocket.py     â† Deprecate or keep
â””â”€â”€ executors/
    â”œâ”€â”€ filesystem.py
    â”œâ”€â”€ process.py
    â””â”€â”€ rag.py                  â† NEW! RAG as executor
```

---

## ğŸ¯ Success Criteria

âœ… User opens Streamlit UI  
âœ… Can chat with Gemini/Ollama  
âœ… RAG automatically activates for relevant queries  
âœ… Can execute tools from chat  
âœ… Responses stream in real-time  
âœ… Beautiful, polished interface  
âœ… All features work together seamlessly  

---

## ğŸ¤” Decision Points

### Question 1: Keep existing HTML UI?
- **Option A**: Keep as backup/alternative
- **Option B**: Replace with Streamlit entirely â­

**Recommendation**: B - Streamlit is easier to iterate

### Question 2: Unified API or separate?
- **Option A**: Single unified API â­
- **Option B**: Keep split

**Recommendation**: A - Much cleaner

### Question 3: When to use RAG?
- **Option A**: Auto-detect â­
- **Option B**: Always use
- **Option C**: User toggle

**Recommendation**: A + C - Auto but allow override

---

## ğŸ¨ Next Steps

**What do you want to do first?**

1. **Git commit** current work?
2. **Create unified API** (faithh_unified_api.py)?
3. **Create Streamlit UI** (chat_ui.py)?
4. **Explore existing RAG** setup first?

I recommend: **1 â†’ 4 â†’ 2 â†’ 3** (commit, explore RAG, build API, build UI)

This gives us clean checkpoints and understanding of what exists!
